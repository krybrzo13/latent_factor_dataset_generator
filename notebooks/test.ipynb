{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76db390",
   "metadata": {},
   "source": [
    "## Simple Multimodal Medical Dataset (Toy Model)\n",
    "\n",
    "### Latent variables\n",
    "\n",
    "| Symbol | Meaning |\n",
    "|:--:|--|\n",
    "| $a$ | age |\n",
    "| $d$ | breast density |\n",
    "| $r$ | risk factor (e.g., family history) |\n",
    "| $s$ | scanner quality |\n",
    "| $z \\in \\{0,1\\}$ | true disease state |\n",
    "\n",
    "---\n",
    "\n",
    "### Core equations\n",
    "\n",
    "#### 1) Disease probability (patient-factor dependent)\n",
    "\n",
    "Let $\\sigma(x)=\\dfrac{1}{1+e^{-x}}$ be the logistic (sigmoid) function.  \n",
    "Define $\\boldsymbol{\\alpha}=(\\alpha_0,\\alpha_1,\\alpha_2,\\alpha_3)$. Then:\n",
    "\n",
    "$$\n",
    "P(z=1)=\\sigma(\\alpha_0+\\alpha_1 a+\\alpha_2 d+\\alpha_3 r)\n",
    "$$\n",
    "\n",
    "#### 2) Lesion parameters (conditional on disease)\n",
    "\n",
    "For $z=1$ only, lesion **size** and **contrast** are defined as:\n",
    "\n",
    "$$\n",
    "\\text{size} = \\beta_0 + \\beta_1 a + \\beta_2 d + \\varepsilon_s\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{contrast} = \\gamma_0 - \\gamma_1 d + \\varepsilon_c\n",
    "$$\n",
    "\n",
    "with noise terms (e.g.) $\\varepsilon_s \\sim \\mathcal{N}(0,\\sigma_s^2)$ and $\\varepsilon_c \\sim \\mathcal{N}(0,\\sigma_c^2)$.\n",
    "\n",
    "#### 3) Generate data\n",
    "\n",
    "$$\n",
    "\\boldsymbol{Image:I} = background(d,s) + z * lesion(size,contrast)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{Radiomics:R} = f(size,contrast,d) + \\varepsilon_{R}\n",
    "$$\n",
    "\n",
    "#### 4) Observed clinical data\n",
    "\n",
    "$$\n",
    "y =\n",
    "\\begin{cases}\n",
    "1, & \\text{if } z = 1 \\text{ and } \\text{random()} > \\eta_{FN} \\\\[4pt]\n",
    "0, & \\text{if } z = 0 \\text{ and } \\text{random()} > \\eta_{FP}\n",
    "\\end{cases}\n",
    "$$\n",
    "where:\n",
    "- $\\eta_{FN}$ — false negative rate  \n",
    "- $\\eta_{FP}$ — false positive rate  \n",
    "- `random()` — uniform sample in $[0,1]$\n",
    "\n",
    "\n",
    "#### 5) Summary\n",
    "\n",
    "| Variable | Generated by | Notes |\n",
    "|:--|:--|:--|\n",
    "| $z$ | logistic(age, density, risk) | true hidden condition |\n",
    "| *image* | function of (density, scanner, lesion params) | visual data |\n",
    "| *radiomics* | derived from lesion params | tabular data |\n",
    "| $y$ | noisy version of $z$ | clinical diagnosis |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path().resolve().parents[0]\n",
    "sys.path.append(str(ROOT))\n",
    "from scripts.ClinicalSynth import ClinicalSynth, Config\n",
    "\n",
    "# --- demanding, realistic setup ---\n",
    "cfg = Config(\n",
    "    H=256, W=256,\n",
    "    seed=42,\n",
    "\n",
    "    # --- latent disease model (rare + weak but real correlations) ---\n",
    "    a0=-4.5,            # low baseline prevalence (~5–8%)\n",
    "    a_age=0.02,         # slightly higher risk with age\n",
    "    a_den=0.35,         # dense breasts -> risk + imaging challenge\n",
    "    a_risk=0.6,         # family history increases risk\n",
    "\n",
    "    # --- diagnostic noise (radiologist uncertainty) ---\n",
    "    eta_fn=0.25,        # 25% missed cancers\n",
    "    eta_fp=0.20,        # 20% overcalls\n",
    "\n",
    "    # --- lesion characteristics (subtle) ---\n",
    "    size_base=10.0,     # moderately small lesion\n",
    "    size_age=0.05,      # slight size increase with age\n",
    "    size_den=2.0,       # dense tissue compresses lesion\n",
    "    con_base=0.9,       # moderately low contrast\n",
    "    con_den=0.6,        # denser breast lowers contrast\n",
    "\n",
    "    # --- imaging conditions ---\n",
    "    bg_base=0.25,                       # noisy parenchyma texture\n",
    "    device_blur={\"A\": 1, \"B\": 3, \"C\": 6},  # varied scanner blur (domain shift)\n",
    ")\n",
    "\n",
    "# --- generate splits ---\n",
    "gen = ClinicalSynth(cfg)\n",
    "train = ClinicalSynth(Config(**{**cfg.__dict__, \"seed\": 123}))\n",
    "val   = ClinicalSynth(Config(**{**cfg.__dict__, \"seed\": 456}))\n",
    "test  = ClinicalSynth(Config(**{**cfg.__dict__, \"seed\": 789}))\n",
    "\n",
    "Xtr = train.sample_batch(1000)  # 1k train\n",
    "Xva = val.sample_batch(100)     # 200 val\n",
    "Xte = test.sample_batch(100)    # 200 test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29c6c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train loss 0.728 acc 0.802 | Val loss 0.692 acc 0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train loss 0.746 acc 0.802 | Val loss 0.677 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train loss 0.623 acc 0.798 | Val loss 0.683 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train loss 0.578 acc 0.796 | Val loss 0.602 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train loss 0.590 acc 0.796 | Val loss 0.643 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train loss 0.783 acc 0.794 | Val loss 0.603 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train loss 0.588 acc 0.792 | Val loss 0.679 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train loss 0.661 acc 0.796 | Val loss 0.617 acc 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train loss 0.524 acc 0.792 | Val loss 0.620 acc 0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train loss 0.505 acc 0.802 | Val loss 0.611 acc 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ClinicalDataset(Dataset):\n",
    "    \"\"\"Wraps arrays from ClinicalSynth into a PyTorch dataset.\"\"\"\n",
    "    def __init__(self, imgs, tabs, y):\n",
    "        self.imgs = torch.tensor(imgs, dtype=torch.float32).unsqueeze(1)\n",
    "        self.tabs = torch.tensor(tabs, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.imgs[i], self.tabs[i], self.y[i]\n",
    "\n",
    "\n",
    "train_ds = ClinicalDataset(*Xtr[:3])\n",
    "val_ds   = ClinicalDataset(*Xva[:3])\n",
    "test_ds  = ClinicalDataset(*Xte[:3])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, n_tab: int):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 5, padding=2), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.tab = nn.Sequential(\n",
    "            nn.Linear(n_tab, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 32), nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16 + 32, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_tab):\n",
    "        vi = self.cnn(x_img).flatten(1)\n",
    "        vt = self.tab(x_tab)\n",
    "        v = torch.cat([vi, vt], dim=1)\n",
    "        return self.fc(v)\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleModel(n_tab=Xtr[1].shape[1]).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def run_epoch(loader, train_mode=True):\n",
    "    if train_mode:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    for img, tab, y in loop:\n",
    "        img, tab, y = img.to(device), tab.to(device), y.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            out = model(img, tab)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "        if train_mode:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        pred = out.argmax(1)\n",
    "        total += y.size(0)\n",
    "        correct += (pred == y).sum().item()\n",
    "        loss_sum += loss.item() * y.size(0)\n",
    "\n",
    "        loop.set_description(f\"{'Train' if train_mode else 'Eval'}\")\n",
    "        loop.set_postfix(loss=loss.item(), acc=correct/total)\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train_mode=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader, train_mode=False)\n",
    "    print(f\"Epoch {epoch+1:02d} | Train loss {tr_loss:.3f} acc {tr_acc:.3f} | \"\n",
    "          f\"Val loss {va_loss:.3f} acc {va_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68de74df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = run_epoch(test_loader, train_mode=False)\n",
    "print(f\"\\nTest accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80988004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "myproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
